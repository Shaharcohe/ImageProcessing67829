import argparse
import math
from abc import ABC, abstractmethod
from typing import Optional, List, Literal

import cv2
import numpy as np
from scipy.signal import convolve2d

RGB_DIM = 3



def gaussian_convolution_vector(dim: int) -> np.ndarray:
    kernel = np.array([math.comb(dim, k) for k in range(dim + 1)])
    return kernel / kernel.sum()


def gaussian_2D_convolution(matrix: np.ndarray,
                            dimension,
                            boundary: Literal['fill', 'wrap', 'symm'] = 'symm') -> np.ndarray:
    """
    Returns the result of a 1D convolution of a matrix with a gaussian kernal.
    :param matrix: The matrix to convolve
    :param dimension: The dimension of the kernel, i.e - 2 means blurring using the closest 2 neighboring pixels.
    :param direction: Horizontal (blurring in rows) or vertical (blurring in columns)
    :param boundary: convolution boundary type. Options are 'fill' - zero padding,
            'wrap' - circular mode, 'symm' - symmetric mode.
    :return: The result of the convolution.
    """
    h_kernel = gaussian_convolution_vector(dimension)
    v_kernel = h_kernel.reshape(-1, 1)
    kernel = np.outer(h_kernel, v_kernel)
    return convolve2d(matrix, kernel, mode='same', boundary='wrap')


def shrink(image, kernel_size=4, boundary: Literal['fill', 'wrap', 'symm'] = 'fill'):
    result = np.zeros((image.shape[0] // 2, image.shape[1] // 2, 3), dtype=image.dtype)
    for channel in range(3):
        blurred = gaussian_2D_convolution(image[:, :, channel], kernel_size, boundary)
        blurred = blurred[::2, ::2]  # Downsample rows
        result[:, :, channel] = blurred
    return result


def enlarge(image: np.ndarray, kernel_size=2, boundary: Literal['fill', 'wrap', 'symm'] = 'symm') -> np.ndarray:
    result = np.zeros((image.shape[0] * 2, image.shape[1] * 2, 3), dtype=image.dtype)
    for channel in range(3):
        # Upsample by adding zero rows and columns
        rows, cols = image[:, :, channel].shape
        upsampled = np.zeros((rows * 2, cols * 2), dtype=image.dtype)
        upsampled[::2, ::2] = image[:, :, channel]

        # Blur vertically and horizontally
        blurred = gaussian_2D_convolution(upsampled, kernel_size, boundary)
        result[:, :, channel] = blurred * 4  # Multiply to normalize intensity
    return result


class Pyramid(ABC):
    """
    Abstract base class for image pyramids. A pyramid represents an image
    at multiple resolutions, enabling multiscale processing.

    Attributes:
        border_type (int): Border type for OpenCV functions (e.g., cv2.BORDER_REPLICATE).
        original_size (tuple[int, int]): Original image size (width, height).
        layers (List[np.ndarray]): List of pyramid layers, generated by the subclass implementation.
    """

    def __init__(self, image: np.ndarray,
                 n_layers: Optional[int] = None,
                 border_type: Optional[int] = cv2.BORDER_REPLICATE,
                 rgb=True):
        if rgb:
            shape = (image.shape[0], image.shape[1])
        else:
            shape = image.shape
        if n_layers is None:
            n_layers = int(math.log2(min(shape)))
        self.border_type = border_type
        self.original_size = image.shape
        self.layers = self.generate_layers(image, n_layers)

    @abstractmethod
    def generate_layers(self, image: np.ndarray, n_layers: int) -> list[np.ndarray]:
        """
        Initializes the Pyramid instance and generates the pyramid layers.

        Args:
            image (np.ndarray): Input image for the pyramid.
            n_layers (Optional[int]): Number of layers in the pyramid. Defaults to maximum layers
                                      based on the smallest dimension of the image.
        """
        raise NotImplementedError()

    def layer(self, k: int, shape: Optional[tuple[int, int]] = None) -> np.ndarray:
        """
        Retrieves a specific layer from the pyramid. Optionally resizes the layer.

        Args:
            k (int): Index of the layer to retrieve.
            size (Optional[tuple[int, int]]): Desired size (width, height) of the layer.
                                              If None, the original size of the layer is returned.

        Returns:
            np.ndarray: The k-th layer of the pyramid.

        Raises:
            ValueError: If the layer index is out of range.
        """
        if k >= len(self.layers) or k < 0:
            raise ValueError("Layer index is out of range")
        if shape is not None:
            layer = self.layers[k]
            ratio = shape[0] / layer.shape[0]
            times = round(math.log2(ratio))
            layer_dtype = layer.dtype
            for i in range(times):
                if layer_dtype is not np.complex128:
                    layer = cv2.pyrUp(layer)
                else:
                    layer = enlarge(layer)
        else:
            layer = self.layers[k]
        return layer

    def __len__(self):
        """
        Returns the number of layers in the pyramid.

        Returns:
            int: Number of layers in the pyramid.
        """
        return len(self.layers)

    def __getitem__(self, idx: int) -> np.ndarray:
        """
        Enables indexing to access pyramid layers.

        Args:
            idx (int): Index of the layer.

        Returns:
            np.ndarray: The layer at the specified index.
        """
        return self.layers[idx]

    def sum(self):
        shape = self.layers[0].shape
        total = self.layers[0]
        for k in range(1, len(self.layers)):
            total += self.layer(k, shape)
        return total


class GaussianPyramid(Pyramid):
    """
    Gaussian Pyramid class, which represents an image pyramid where each layer
    is a smoothed and downsampled version of the previous layer.
    """

    def generate_layers(self, image: np.ndarray, n_layers: int) -> List[np.ndarray]:
        """
        Generates layers of the Gaussian Pyramid.

        Args:
            image (np.ndarray): Input image for the pyramid.
            n_layers (int): Number of layers to generate.

        Returns:
            List[np.ndarray]: List of Gaussian pyramid layers.
        """
        layers = []
        layers.append(image.copy())
        for k in range(1, n_layers):
            if layers[-1].dtype is not np.complex128:
                layers.append(cv2.pyrDown(layers[-1]))
            else:
                layers.append(shrink(layers[-1]))
        return layers


class LaplacianPyramid(Pyramid):
    """
    Laplacian Pyramid class, which represents an image pyramid where each layer
    contains the difference between successive Gaussian layers.
    """

    def generate_layers(self, image: np.ndarray, n_layers: int) -> List[np.ndarray]:
        """
        Generates layers of the Laplacian Pyramid using the Gaussian Pyramid.

        Args:
            image (np.ndarray): Input image for the pyramid.
            n_layers (int): Number of layers to generate.

        Returns:
            List[np.ndarray]: List of Laplacian pyramid layers.
        """
        gaussian_pyramid = GaussianPyramid(image, n_layers, self.border_type)
        layers = []
        for k in range(len(gaussian_pyramid) - 1):
            layer = gaussian_pyramid.layer(k)
            shape = layer.shape
            next_layer = gaussian_pyramid.layer(k + 1, shape)
            laplacian_k = layer - next_layer
            layers.append(laplacian_k)
        layers.append(gaussian_pyramid[-1])
        return layers


class BlendedPyramid(Pyramid):
    """ Data structure for blending two images together. """

    def __init__(self, first_image: np.ndarray,
                 second_image: np.ndarray,
                 mask: np.ndarray):
        laplacian_a = LaplacianPyramid(first_image)
        laplacian_b = LaplacianPyramid(second_image)
        gaussian = GaussianPyramid(mask)
        self.n_layers = len(laplacian_a)
        self.layers = self.generate_layers(laplacian_a, laplacian_b, gaussian)

    def generate_layers(self, lap_a: LaplacianPyramid, lap_b: LaplacianPyramid, g: GaussianPyramid):
        layers = []
        for k in range(self.n_layers):
            layer_k = (g[k] * lap_a[k]) + ((1 - g[k]) * lap_b[k])
            layers.append(layer_k)
        return layers


def blended_image(image_a, image_b, mask):
    if not (mask.shape == image_a.shape == image_b.shape):
        raise ValueError('Images and mask must have the same dimensions.')
    image = BlendedPyramid(image_a, image_b, mask).sum()
    return image


def hybrid_image(image_a, image_b, mask):
    if image_a.shape != image_b.shape:
        raise ValueError('Images must have the same dimensions.')
    fft_a = np.fft.fft2(image_a).astype(np.complex128)
    fft_b = np.fft.fft2(image_b).astype(np.complex128)
    fft_hybrid = mask * fft_b + (1-mask) * fft_a
    image = np.abs(np.fft.ifft2(fft_hybrid))
    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    return image


class Processor:
    @staticmethod
    def pad_to_power_of_two(image):
        """
        Pads an image so that its dimensions are powers of 2.

        Args:
            image (np.ndarray): Input image (2D or 3D NumPy array).

        Returns:
            np.ndarray: Padded image with dimensions as powers of 2.
        """
        # Get current height and width
        height, width = image.shape[:2]

        # Calculate the nearest powers of 2
        new_height = 2 ** math.ceil(math.log2(height))
        new_width = 2 ** math.ceil(math.log2(width))

        # Calculate padding for each side
        pad_top = (new_height - height) // 2
        pad_bottom = new_height - height - pad_top
        pad_left = (new_width - width) // 2
        pad_right = new_width - width - pad_left

        # Apply padding with zeros
        padded_image = cv2.copyMakeBorder(
            image, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(0, 0, 0)
        )

        return padded_image

    @staticmethod
    def preprocess_images(image_a, image_b, mask: Optional[np.ndarray] = None):
        p_image_a = image_a.astype(np.int16)
        p_image_b = image_b.astype(np.int16)
        if mask is not None:
            mask = mask.astype(np.int16)
        shape = image_a.shape[:2][::-1]
        p_image_b = cv2.resize(p_image_b, shape)
        if mask is not None:
            mask = cv2.resize(mask, shape)
        p_image_a = Processor.pad_to_power_of_two(p_image_a)
        p_image_b = Processor.pad_to_power_of_two(p_image_b)
        if mask is not None:
            mask = Processor.pad_to_power_of_two(mask)
        return p_image_a, p_image_b, mask, shape[::-1]

    @staticmethod
    def remove_padding(image, original_size):
        # Get the current height and width of the padded image
        padded_height, padded_width = image.shape[:2]
        original_height, original_width = original_size

        # Calculate the cropping dimensions
        pad_top = (padded_height - original_height) // 2
        pad_bottom = pad_top + original_height
        pad_left = (padded_width - original_width) // 2
        pad_right = pad_left + original_width

        # Crop the image to the original size
        cropped_image = image[pad_top:pad_bottom, pad_left:pad_right]

        return cropped_image

    @staticmethod
    def load_image(path, load_grayscale):
        if load_grayscale:
            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        else:
            img = cv2.imread(path)
        if img is None:
            raise FileNotFoundError(f"Path {path} not found.")
        return img

    @staticmethod
    def create_elliptic_mask(width, height, threshold) -> np.ndarray:
        mask = np.zeros((height, width, RGB_DIM), dtype=np.int16)
        # Define ellipse parameters
        center = (width // 2, height // 2)  # Ellipse center
        axes = (int(round(width * threshold)), int(round(height * threshold)))
        angle = 0  # Ellipse rotation angle
        start_angle = 0  # Start angle of the ellipse
        end_angle = 360  # End angle of the ellipse
        mask = cv2.ellipse(mask, center, axes, angle, start_angle, end_angle, color=255, thickness=-1)
        return mask

    @staticmethod
    def preprocess_mask(mask, kernel_size):
        # Normalize mask to [0, 1]
        mask = mask.astype(np.float32) / 255.0 if mask.max() > 1 else mask.astype(np.float32)
        if kernel_size is not None:
            mask = cv2.blur(mask, (kernel_size, kernel_size))
        return mask




def main(img_a_path, img_b_path, mode, mask, kernel_size, threshold, output_path):
    grayscale = (mask == 'hybrid')
    image_a = Processor.load_image(img_a_path, grayscale)
    image_b = Processor.load_image(img_b_path, grayscale)

    if mode == 'blending':
        mask = Processor.load_image(mask)
    else:
        width, height = image_a.shape[:2][::-1]
        mask = Processor.create_elliptic_mask(width, height, threshold)
    mask = Processor.preprocess_mask(mask, kernel_size)
    image_a, image_b, mask, original_shape = Processor.preprocess_images(image_a, image_b, mask)
    if mode == 'hybrid':
        image = hybrid_image(image_a, image_b, mask)
    else:
        image = blended_image(image_a, image_b, mask)
    image = Processor.remove_padding(image, original_shape)
    cv2.imwrite(output_path, image)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Preprocess two images and an optional mask by padding to powers of two, then remove padding."
    )

    # Add arguments
    parser.add_argument("image_a", help="Path to the first image.")
    parser.add_argument("image_b", help="Path to the second image.")
    parser.add_argument("--mode", choices=["hybrid", "blending"])
    parser.add_argument("--mask", help="Path to the optional mask image.", default=None)
    parser.add_argument("--kernel_size",
                        help="Kernel size to blurr the mask.", default=None,
                        type=int)
    parser.add_argument("--threshold",
                        help="Hybridization frequency ratio.",
                        default=0.5,
                        type=float)
    parser.add_argument("--output_path", help="Directory to save the processed results.",
                        default="output.jpg")
    args = parser.parse_args()
    if args.threshold < 0 or args.threshold > 1:
        raise ValueError("Threshold value must be between 0 and 1.")

    main(args.image_a, args.image_b, args.mode, args.mask, args.kernel_size, args.threshold, args.output_path)
